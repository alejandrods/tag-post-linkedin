{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "files = glob.glob(\"./scraping/programming/*.txt\")\n",
    "\n",
    "prog_sent = []\n",
    "for f in files:\n",
    "    sent = pickle.load(open(f, \"rb\"))\n",
    "    prog_sent.append(sent)\n",
    "\n",
    "posts_flatten = [y for x in prog_sent for y in x]\n",
    "set_posts_flatten = list(set(posts_flatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length posts:  7988\n",
      "Set length posts:  2875\n"
     ]
    }
   ],
   "source": [
    "print('Length posts: ', len(posts_flatten))\n",
    "print('Set length posts: ', len(set_posts_flatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: \n",
      "------------\n",
      "Great experience revising again the basics of Python with Coursera \n",
      "hashtag\n",
      "#python \n",
      "hashtag\n",
      "#pythonprogramming \n",
      "hashtag\n",
      "#coding \n",
      "hashtag\n",
      "#pythonprogramminglanguage \n",
      "hashtag\n",
      "#programming \n",
      "hashtag\n",
      "#computerprogramming # \n",
      "hashtag\n",
      "#coursera \n",
      "hashtag\n",
      "#python3 \n",
      "hashtag\n",
      "#programmer \n",
      "hashtag\n",
      "#codinglife \n",
      "hashtag\n",
      "#codingisfun \n",
      "hashtag\n",
      "#learntocode \n",
      "hashtag\n",
      "#programminglife\n",
      "\n",
      "\n",
      "Example 2: \n",
      "------------\n",
      "hashtag\n",
      "#StudyGuides \n",
      "hashtag\n",
      "#College \n",
      "hashtag\n",
      "#Amazon \n",
      "hashtag\n",
      "#Statistics \n",
      "hashtag\n",
      "#Analytics \n",
      "hashtag\n",
      "#DataScience \n",
      "hashtag\n",
      "#Physics \n",
      "hashtag\n",
      "#Exams\n",
      "‚≠ê‚≠ê‚≠ê‚≠ê‚≠êANALYTICS/STATISTICS/DATA SCIENCE\n",
      "üåüüåüüåüüåüüåü Probability and Statistics: https://lnkd.in/gMsBmgr\n"
     ]
    }
   ],
   "source": [
    "print('Example 1: ')\n",
    "print('------------')\n",
    "print(set_posts_flatten[20])\n",
    "print('\\n\\nExample 2: ')\n",
    "print('------------')\n",
    "print(set_posts_flatten[-345])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = set_posts_flatten[2345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Best \\nhashtag\\n#Statistics \\nhashtag\\n#Books of All-Time. \\nhashtag\\n#BigData \\nhashtag\\n#Analytics \\nhashtag\\n#DataScience \\nhashtag\\n#IoT \\nhashtag\\n#IIoT \\nhashtag\\n#Python \\nhashtag\\n#RStats \\nhashtag\\n#TensorFlow \\nhashtag\\n#Java \\nhashtag\\n#JavaScript \\nhashtag\\n#ReactJS \\nhashtag\\n#GoLang \\nhashtag\\n#CloudComputing \\nhashtag\\n#Serverless \\nhashtag\\n#DataScientist \\nhashtag\\n#Linux \\nhashtag\\n#Programming \\nhashtag\\n#Coding \\nhashtag\\n#100DaysofCode \\nhttps://bit.ly/34lpMpr'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best hashtag #statistics hashtag #books of all-time. hashtag #bigdata hashtag #analytics hashtag #datascience hashtag #iot hashtag #iiot hashtag #python hashtag #rstats hashtag #tensorflow hashtag #java hashtag #javascript hashtag #reactjs hashtag #golang hashtag #cloudcomputing hashtag #serverless hashtag #datascientist hashtag #linux hashtag #programming hashtag #coding hashtag #100daysofcode https://bit.ly/34lpmpr\n"
     ]
    }
   ],
   "source": [
    "test_clean = clean_text(test)\n",
    "print(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cloudcomputing', 'iiot', 'analytics', 'linux', 'datascience', 'reactjs', 'serverless', 'iot', 'tensorflow', 'datascientist', 'javascript', 'rstats', 'statistics', 'programming', '100daysofcode', 'python', 'java', 'books', 'golang', 'bigdata', 'coding']\n"
     ]
    }
   ],
   "source": [
    "def extract_hash_tags(s):\n",
    "    return set(part[1:] for part in s.split() if part.startswith('#'))\n",
    "\n",
    "test_ = extract_hash_tags(test_clean)\n",
    "print(list(test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2hash = {}\n",
    "\n",
    "for el in set_posts_flatten[:1]:\n",
    "    # Clean text\n",
    "    cl_el = clean_text(el)\n",
    "    # Delete hashtags\n",
    "    no_hash_el = re.sub('hashtag #', ' ', cl_el)\n",
    "    # Create dictionary with hashtags\n",
    "    ext_hash = extract_hash_tags(cl_el)\n",
    "    \n",
    "    sent2hash[no_hash_el] = ext_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a lot of my friends who had offers are getting laid off or offers are getting revoked, putting them back in the job market. i just conducted a mock coding interview for one of them and it was a lot of fun and i would like to do more, because i want to help other people and it helps me get a better idea of what the interviewer wants. so if anyone here wants to do a mock interview (either as the interviewer or interviewee) shoot me a dm and we can figure something out. my main languages are java and python but i can basically interview you in any language you want.  jobsearch  jobseekers  interview  algorithms  python  resume  java': {'algorithms',\n",
       "  'interview',\n",
       "  'java',\n",
       "  'jobsearch',\n",
       "  'jobseekers',\n",
       "  'python',\n",
       "  'resume'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = '!\"$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "def strip_list_noempty(mylist):\n",
    "    newlist = (item.strip() if hasattr(item, 'strip') else item for item in mylist)\n",
    "    return [item for item in newlist if item != '']\n",
    "\n",
    "def clean_punct(text): \n",
    "    words = nltk.word_tokenize(text)\n",
    "    print(words)\n",
    "    punctuation_filtered = []\n",
    "    regex = re.compile('[%s]' % re.escape(punct))\n",
    "    remove_punctuation = str.maketrans(' ', ' ', punct)\n",
    "    #for w in words:\n",
    "    #    if w in tags_features:\n",
    "    #        punctuation_filtered.append(w)\n",
    "    #    else:\n",
    "    #        punctuation_filtered.append(regex.sub('', w))\n",
    "  \n",
    "    #filtered_list = strip_list_noempty(punctuation_filtered)\n",
    "    print(remove_punctuation)\n",
    "    return ' '.join(map(str, remove_punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'best', 'hashtag', '#', 'statistics', 'hashtag', '#', 'books', 'of', 'all-time', '.', 'hashtag', '#', 'bigdata', 'hashtag', '#', 'analytics', 'hashtag', '#', 'datascience', 'hashtag', '#', 'iot', 'hashtag', '#', 'iiot', 'hashtag', '#', 'python', 'hashtag', '#', 'rstats', 'hashtag', '#', 'tensorflow', 'hashtag', '#', 'java', 'hashtag', '#', 'javascript', 'hashtag', '#', 'reactjs', 'hashtag', '#', 'golang', 'hashtag', '#', 'cloudcomputing', 'hashtag', '#', 'serverless', 'hashtag', '#', 'datascientist', 'hashtag', '#', 'linux', 'hashtag', '#', 'programming', 'hashtag', '#', 'coding', 'hashtag', '#', '100daysofcode', 'https', ':', '//bit.ly/34lpmpr']\n",
      "{32: 32, 33: None, 34: None, 35: None, 36: None, 37: None, 38: None, 39: None, 40: None, 41: None, 42: None, 43: None, 44: None, 46: None, 47: None, 58: None, 59: None, 60: None, 61: None, 62: None, 63: None, 64: None, 91: None, 92: None, 93: None, 94: None, 95: None, 96: None, 123: None, 124: None, 125: None, 126: None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 58 59 60 61 62 63 64 91 92 93 94 95 96 123 124 125 126'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_punct(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
